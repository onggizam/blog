# 시계열 자원 사용량 데이터를 다루며 – ETL 파이프라인 구축기

_by Seunggi Hong_

## 들어가며

대규모 IT 환경에서는 서버와 PC의 자원 사용 현황을 정기적으로 수집하는 것이 필수적이다.
CPU, GPU, MEMORY 같은 메트릭은 단순 모니터링을 넘어, **장기적인 패턴 분석과 운영 효율화의 기초 데이터**가 된다.

하지만 수천 개의 엔드포인트(Windows, Windows Server, Linux Server)에서 5분마다 데이터가 쏟아져 들어온다면, 단순 수집만으로는 한계가 명확하다.
나는 이 문제를 해결하기 위해 **Apache Airflow 기반 ETL 파이프라인**을 설계했고, 이를 통해 데이터가 안정적으로 적재·정제·활용될 수 있는 기반을 마련했다.

## 단순 수집의 한계

처음에는 단순히 주기적으로 수집된 데이터를 받아 파일로 저장하는 방식만 고려했다. 하지만 곧 여러 문제가 드러났다.

1. **데이터 폭증**

   - 수천 개 엔드포인트 × 5분 주기 수집 → 한시간 12개 하루 288개의 데이터, 즉 하루만 지나도 수십 GB 이상 발생
   - 파일 단위로만 쌓이면 관리가 불가능하다.

2. **검색 불가능**

   - 단순 파일 저장만으로는 “특정 엔드포인트의 CPU 사용률 추이” 같은 단순 질의조차 수 분\~수십 분 소요된다.
   - 실시간 대시보드나 운영 지표 제공은 사실상 불가능했다.

3. **데이터 품질 불확실**

   - 누락, 결측치, 잘못된 범위 값(예: CPU > 100%)이 빈번히 포함되어 신뢰도가 낮다.
   - 단순 적재만으로는 정제·검증이 불가능하다.

4. **운영체제별 불일치**

   - Windows, Windows Server, Linux Server에서 추출되는 필드와 단위가 서로 달랐다.
   - 통합 스키마가 없으면 교차 비교나 집계 분석이 불가능했다.

5. **분석/활용 제약**

   - 장기 트렌드 분석이나 머신러닝 적용을 위해서는 시계열 정합성이 필요하다.
   - 단순 파일 누적 방식으로는 이를 확보하기 어려웠다.

이 한계들이 분명해지면서, 단순한 로그 수집을 넘어 **ETL 파이프라인**으로 전환하여 관리해야 하는 필요성이 커졌다.

## 수집: 원본을 안전하게 받아들이기

각 엔드포인트에서 추출된 데이터를 **HTTP Listener**로 수신하고, **Landing 영역**에 CSV 형태로 저장했다.
이 단계에서 내가 신경 쓴 것은 **원본 데이터의 무결성과 재처리 가능성**이었다.

- **Landing 구조**: 5분 단위로 파일을 저장, 날짜/시간 디렉토리로 구분
- **Immutable 원칙**: 원본은 절대 수정하지 않고 보존
- **운영체제 다양성 대응**: Windows/Windows Server/Linux Server 간 필드 차이를 고려해, 이후 단계에서 통합 처리

## 처리: Airflow로 시간 단위 ETL

데이터는 5분마다 들어오지만, **ETL은 1시간 단위 배치**로 수행했다.
Airflow DAG을 통해 원본 데이터를 검증하고 정제한 후, 데이터베이스에 적재했다.

- **검증**: 누락 필드, 범위를 벗어난 값(예: CPU > 100%), 데이터 이상치 체크
- **정제**: OS별 필드 통합, CPU/GPU 사용률 클리핑, 단위 일관성 확보
- **집계**: 엔드포인트별 평균·최댓값 합산
- **적재**: 정제된 데이터를 분석용 데이터베이스에 로딩

## 저장: 대규모 데이터베이스 기반 분석 구조

정제된 데이터는 **대규모 병렬 처리를 지원하는 데이터베이스**에 적재해 분석과 탐색에 활용됐다.

- **테이블 설계**: 날짜/시간을 기준으로 파티션 컬럼 구성 → 시계열 쿼리 성능 확보
- **SQL 기반 접근**: 대규모 데이터에도 빠른 응답이 가능한 병렬 처리 구조
- **운영체제 구분 컬럼**: OS별 비교/집계를 지원하도록 스키마에 반영

덕분에 운영팀은 데이터베이스에서 최근 1시간 데이터를 빠르게 조회하고 대시보드를 구성할 수 있었으며, 분석팀은 수개월치 데이터를 SQL 기반으로 집계·분석할 수 있었다.

## 경험에서 얻은 교훈

1. **원본 보존은 보험이다**
   시계열 데이터는 새로운 규칙이나 지표 정의가 등장할 수 있다. Raw 데이터를 남겨둔 덕분에 언제든 재처리가 가능했다.

2. **Noise를 다루는 방법이 곧 데이터 품질이다**
   CPU/GPU/MEMORY 지표에는 튀는 값과 결측이 많다. 단순 평균보다 **퍼센타일 기반 집계**가 안정적인 인사이트를 제공했다.

3. **Batch와 실시간 사이의 균형**
   모든 데이터를 실시간으로 다룰 필요는 없다. 운영 안정성을 우선해 1시간 단위로 묶었고, 필요하면 스트리밍으로 확장 가능하도록 설계했다.

4. **운영체제 다양성 고려는 필수**
   Windows, Windows Server, Linux Server에서 오는 데이터가 제각각이었기 때문에, 이를 **공통 스키마로 맞추는 과정**이 빅데이터 분석의 전제 조건이었다.

## 마치며

CPU, GPU, MEMORY 같은 시계열 데이터는 단순히 많이 모은다고 가치가 생기지 않는다.
**단순 수집만으로는 데이터 폭증·품질 문제·검색 불가능·운영체제 차이** 같은 한계가 분명했다.

Airflow ETL 파이프라인과 대규모 데이터베이스 기반 저장 구조를 도입하면서, 데이터는 비로소 **신뢰성 있는 자산**으로 전환되었고, 분석과 운영 모두에서 활용할 수 있는 토대가 마련됐다.

> 교훈: 시계열 데이터는 **단순 적재가 아니라, 정제·검증·표준화 과정을 거쳐야 비로소 운영과 분석에 쓸 수 있다.**

앞으로는 이 기반 위에 더 지능적인 분석 기법과 자동화된 운영 체계를 얹어, 한 단계 진화시킬 계획이다.

# 분산 학습, Horovod에서 Ray로 갈아탄 이유

_by Seunggi Hong_

## 왜 분산 학습인가?

머신러닝과 딥러닝은 이제 단일 GPU로 처리하기 어려운 수준까지 확장되었습니다.

- 데이터셋은 수십 GB에서 수 TB로 커지고,
- 모델 파라미터는 수백만에서 수십억 단위까지 불어났습니다.

이런 상황에서 단일 노드 학습은 **시간과 비용** 면에서 비효율적일 뿐만 아니라, 실제 산업 현장에서는 **실시간성 요구**를 만족하기 어렵습니다.

특히 스마트 온실 같은 IoT 환경에서는 센서에서 밀려드는 데이터를 빠르게 학습/추론해야 하므로, **분산 학습(distributed training)**과 **분산 추론(distributed inference)**은 필수적입니다.

## Horovod를 선택했던 이유와 그 한계

초기에는 **Horovod**를 선택했습니다. Uber에서 개발한 Horovod는 **AllReduce 알고리즘** 기반으로 파라미터를 효율적으로 동기화하는 툴로, 대규모 딥러닝 학습에서 상당한 성능을 보여줍니다.

### 👍 장점

- **빠른 학습 속도**: TensorFlow, PyTorch, MXNet 등 주요 프레임워크와 통합되어, GPU 클러스터에서 빠른 분산 학습이 가능.
- **MPI 기반 최적화**: GPU 간 통신 최적화가 잘 되어 있어 성능 벤치마크에서는 여전히 좋은 결과를 냅니다.

### 👎 단점

그러나 실무 환경에서는 문제가 있었습니다.

1. **종속성 민감성**  
   Horovod는 CUDA, NCCL, OpenMPI, TensorFlow/PyTorch 버전에 매우 민감합니다. 한 버전만 어긋나도 빌드가 깨지고, 디버깅에 며칠씩 소요되곤 했습니다.
2. **쿠버네티스 통합 어려움**  
   Horovod를 쿠버네티스에서 운영하려면 MPI Operator, Helm Chart, 각종 ConfigMap까지 설정해야 해서 운영 복잡도가 높습니다.
3. **워크로드 제한**  
   Horovod는 학습 단계에는 강력하지만, 데이터 전처리, 온라인 추론, 강화학습 등 다양한 워크로드를 지원하기에는 한계가 있습니다.

즉, 연구 환경에서는 유용했지만, **클라우드 네이티브 프로덕션 환경**에서는 불편한 점이 많았습니다.

## Ray로 전환한 이유

이런 문제를 해결하기 위해 선택한 것이 바로 **Ray**입니다. Ray는 처음부터 **범용 분산 프레임워크**로 설계되었습니다. 단순히 학습뿐만 아니라, **데이터 처리 → 학습 → 서빙 → 튜닝**까지 하나의 런타임에서 관리할 수 있습니다.

### Ray의 장점

1. **쿠버네티스 네이티브**  
   Ray Operator를 통해 손쉽게 RayCluster를 배포할 수 있으며, Pod이 죽으면 자동으로 복구됩니다. Horovod보다 훨씬 간단하게 쿠버네티스 환경에 녹아듭니다.

2. **Pythonic 인터페이스**  
   기존 Python 코드를 크게 수정하지 않고 `@ray.remote` 데코레이터만 붙여도 분산화가 가능합니다. 진입 장벽이 낮아 학습/실험 속도가 빨라집니다.

3. **멀티 워크로드 지원**

   - 데이터 전처리 (Ray Data)
   - 학습 (Ray Train)
   - 하이퍼파라미터 튜닝 (Ray Tune)
   - 온라인 추론/서빙 (Ray Serve)
   - 강화학습 (RLlib)  
     한 런타임에서 모두 지원하므로, 전체 ML 파이프라인을 **엔드투엔드**로 다룰 수 있습니다.

4. **세밀한 자원 관리**  
   Ray Scheduler는 GPU/CPU 리소스를 Pod 단위로 동적으로 할당할 수 있습니다. 예를 들어, 전처리에는 CPU만, 학습에는 GPU를, 추론에는 혼합 자원을 쓰는 식으로 최적화가 가능합니다.

## Horovod → Ray 전환 과정에서의 인사이트

실제로 Ray로 전환하면서 느낀 점은 단순한 “성능 향상”이 아니라, **운영 효율성**의 차이였습니다.

- **환경 세팅 시간 단축**: Horovod 때는 종속성 문제로 환경 구축에 며칠씩 걸리던 것이, Ray에서는 하루 이내로 끝났습니다.
- **워크로드 통합**: 데이터 전처리, 학습, 추론을 모두 Ray 클러스터에서 돌리니 관리 포인트가 줄어들었습니다.
- **Airflow·MLflow 연계 용이**: 기존 MLOps 파이프라인과 Ray를 붙이는 것이 훨씬 단순해졌습니다.
- **스케일 아웃의 용이함**: 학습 데이터가 10배 늘어나도 Ray Worker Pod만 확장하면 대응이 가능했습니다.

## Horovod vs Ray 비교 요약

| 항목      | Horovod                   | Ray                                            |
| --------- | ------------------------- | ---------------------------------------------- |
| 주요 목적 | 대규모 분산 학습 최적화   | 범용 분산 컴퓨팅 플랫폼                        |
| 장점      | 빠른 GPU 학습, MPI 최적화 | Kubernetes 친화적, 멀티 워크로드 지원          |
| 단점      | 종속성 민감, 운영 복잡성  | 일부 워크로드에서는 아직 성숙도 낮음           |
| 적합 환경 | 연구용 학습 클러스터      | 프로덕션 ML 파이프라인, 클라우드 네이티브 환경 |

## 맺음말

Horovod는 여전히 학술적 연구나 고정된 환경에서의 학습에는 좋은 선택입니다. 그러나 실제 프로덕션 환경에서는 **운영 효율성과 확장성**이 더 중요합니다.

Ray로 전환한 경험은, “분산 학습은 단순히 학습 속도의 문제가 아니라, **클라우드 네이티브 환경에서의 운영 전략**이다”라는 사실을 다시금 확인시켜 주었습니다.

앞으로 분산 학습 도구를 선택할 때는, **벤치마크 성능 수치**만이 아니라 **운영 편의성과 파이프라인 통합성**까지 고려하는 것이 필수입니다.

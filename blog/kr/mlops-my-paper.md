# 컨테이너 기반 클라우드 위에서 구현하는 Scalable MLOps

_by Seunggi Hong_

**_이 글은 제가 직접 작성하여 한국콘텐츠학회 ICCC 2024에 제출한 논문을 기반으로 작성되었습니다._**

## 왜 농업에서 MLOps인가?

AI/ML 모델을 프로덕션 환경에 올려본 경험이 있다면, **코드 작성보다 운영이 훨씬 어렵다**는 점을 공감할 겁니다. 특히 스마트 온실처럼 실시간 센서 데이터가 지속적으로 들어오는 환경에서는, 데이터 파이프라인의 병목이나 모델 배포 지연은 곧 **작물 성장 환경 제어 실패**로 이어질 수 있습니다.

따라서 단순히 모델을 만드는 데서 끝나지 않고, **데이터 수집–전처리–학습–배포–추론–제어** 전 과정을 안정적으로 운영하는 **MLOps 체계**가 필수입니다.

## 아키텍처 설계 철학

<p align="center">
  <img src="../../assets/iccc_flow.png" alt="ICCC Flow Diagram" width="600"/>
</p>

제가 설계한 프레임워크는 “**모든 것을 컨테이너화(Containerize Everything)**”라는 원칙에 기반합니다.

- **Kubernetes** 위에 각 서비스를 독립된 Pod으로 올려서, 장애 격리·자동 복구·수평 확장을 지원합니다.
- 각 단계는 느슨하게 결합되어, 특정 모듈만 교체·업그레이드하기도 용이합니다.
- 데이터 엔지니어, ML 엔지니어, 운영자가 동일한 인프라 위에서 협업할 수 있습니다.

## 핵심 구성 요소

### 1. 데이터 인제스트 (Ingestion)

- **Apache Kafka REST Proxy**
  스마트 온실 센서와 제어 장치에서 들어오는 시계열 데이터를 안정적으로 수집합니다.
  → REST Proxy를 둠으로써 HTTP 기반 장치와도 쉽게 통신 가능.

### 2. 데이터 레이크 (Storage)

- **MongoDB**: 빠른 조회와 관리가 필요한 메타데이터 저장.
- **HDFS**: 대규모 원본 데이터와 학습용 대용량 데이터셋 저장.

두 계층을 조합해 **속도 + 용량** 두 마리 토끼를 잡았습니다.

### 3. 분산 학습 환경

- **Ray**를 통해 병렬 학습 및 분산 인퍼런스 지원.
  Spark에 비해 lightweight하면서 Pythonic 코드로 빠르게 분산화 가능.

### 4. 워크플로우 오케스트레이션

- **Apache Airflow**로 전체 파이프라인을 DAG(Directed Acyclic Graph) 단위로 관리.
  데이터 전처리, 학습, 평가, 배포 단계를 태스크로 정의해 자동 실행 및 모니터링.

### 5. 모델 관리 및 서빙

- **MLflow**로 모델 버전 관리, 실험 추적, 아티팩트 관리 수행.
- Kubernetes Pod 단위로 모델을 서빙 → Canary 배포나 Blue-Green 전략 적용 용이.

## Pod 단위 파이프라인의 장점

전통적으로는 Spark DataFrame을 그대로 넘기면서 전처리–학습을 이어붙였는데, 이는 **확장성 문제**를 야기했습니다.

제가 제안한 방식은 **전처리 Pod과 학습 Pod을 완전히 분리**합니다.

- 전처리 Pod에서 HDFS/MongoDB에 결과 저장.
- 학습 Pod은 해당 결과를 읽어와 모델 학습 진행.

이렇게 하면:

- 전처리 파이프라인만 따로 확장 가능.
- 학습 파이프라인만 새 모델로 교체 가능.
- 자원(Resource)을 세밀하게 할당 → GPU/CPU 클러스터 활용 극대화.

## 운영상의 고려사항

1. **네트워크 I/O 최적화**
   Pod 간 데이터 전송은 지연(latency) 요인이 될 수 있으므로,

   - 로컬 캐싱,
   - 데이터 압축,
   - GPU 노드와 스토리지를 같은 영역(Zone)에 배치
     등이 필요합니다.

2. **모니터링 및 로깅**

   - Prometheus + Grafana로 리소스 사용량 및 모델 성능 모니터링.
   - Airflow + MLflow 이벤트를 통합 로깅하여 추적성 확보.

3. **보안**
   센서–클라우드 간 통신은 반드시 TLS/SSL 적용.
   제어 메시지는 인증·권한 관리 없이는 위험 요소가 됩니다.

## 기대 효과

- **확장성**: 데이터가 10배 늘어나도, 단순히 Pod 스케일 아웃으로 대응 가능.
- **유연성**: 전처리 알고리즘, 학습 모델, 배포 전략을 독립적으로 교체 가능.
- **실시간성**: 데이터 인제스트부터 제어 메시지 송출까지 병목 없는 파이프라인 확보.

결국 이 프레임워크는 스마트 온실뿐 아니라, **스마트 팩토리·스마트 시티·스마트 에너지** 같은 모든 IoT 기반 AI 응용 분야에 그대로 확장할 수 있습니다.

## 맺음말

AI 연구와 실제 서비스 운영 사이에는 큰 간극이 있습니다. 제가 제안한 **컨테이너 기반 MLOps 프레임워크**는 그 간극을 줄이는 시도입니다.

스마트 온실이라는 특정 도메인에서 출발했지만, 본질적으로는 **“데이터-학습-배포”를 컨테이너 네이티브 환경에서 어떻게 효율적으로 이어붙일 것인가**라는 질문에 대한 답입니다.

앞으로는 더 많은 산업이 이런 **엔드투엔드 MLOps 체계**를 필요로 할 것이고, Kubernetes와 같은 클라우드 네이티브 기술이 그 토대가 될 것입니다.

## 원문 논문 보기

[![Read Paper](https://img.shields.io/badge/Scalable%20MLOps%20Paper-Click%20Here-blue?style=for-the-badge&logo=readthedocs)](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE12050136)
